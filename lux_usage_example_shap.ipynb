{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lux.lux import LUX\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lux.lux import LUX\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "features = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "target = 'calss'\n",
    "rs=42\n",
    "fraction=0.3\n",
    "\n",
    "#create daatframe with columns names as strings (LUX accepts only DataFrames withj string columns names)\n",
    "df_iris = pd.DataFrame(iris.data,columns=features)\n",
    "df_iris[target] = iris.target\n",
    "\n",
    "#train classifier\n",
    "train, test = train_test_split(df_iris, random_state=rs)\n",
    "clf = svm.SVC(probability=True, random_state=rs)\n",
    "clf.fit(train[features],train[target])\n",
    "clf.score(test[features],test[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Withoiut uncertainty of predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but SVC was fitted with feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In fact using: 0.8839285714285714 samples from train set wiuth class balance: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['IF petal_length  < 2.45 THEN class = 0 # 1.0\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pick some instance from datasetr\n",
    "iris_instance = train[features].sample(1, random_state=42).values\n",
    "iris_instance\n",
    "\n",
    "#train lux on neighbourhood equal 30% instances\n",
    "lux = LUX(predict_proba = lambda x: np.round(clf.predict_proba(x)), neighborhood_size=int(len(train)*fraction),max_depth=2,  node_size_limit = 1, grow_confidence_threshold = 0 )\n",
    "lux.fit(train[features], train[target], instance_to_explain=iris_instance,class_names=[0,1,2],n_jobs=4)\n",
    "\n",
    "#see the justification of the instance being classified for a given class\n",
    "lux.justify(np.array(iris_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "#calculate decision tree score over this dataset\n",
    "import sys\n",
    "sys.path.append('./pyuid3')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pyuid3.data import Data\n",
    "data = Data.parse_dataframe(test[features+[target]])\n",
    "    \n",
    "predictions = [int(x.get_name()) for x in lux.uid3.predict(data.instances)]\n",
    "print(f'Accuracy : {accuracy_score(predictions, test[target])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: mediationTree Pages: 1 -->\n",
       "<svg width=\"251pt\" height=\"344pt\"\n",
       " viewBox=\"0.00 0.00 250.50 344.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 340)\">\n",
       "<title>mediationTree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-340 246.5,-340 246.5,4 -4,4\"/>\n",
       "<!-- 8780664239824 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>8780664239824</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"133.5,-336 23.5,-336 23.5,-298 133.5,-298 133.5,-336\"/>\n",
       "<text text-anchor=\"middle\" x=\"78.5\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> petal_length</text>\n",
       "<text text-anchor=\"middle\" x=\"78.5\" y=\"-305.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n",
       "</g>\n",
       "<!-- 8780664248863 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>8780664248863</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"59,-232 0,-232 0,-149 59,-149 59,-232\"/>\n",
       "<text text-anchor=\"middle\" x=\"29.5\" y=\"-216.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> class</text>\n",
       "<text text-anchor=\"middle\" x=\"29.5\" y=\"-201.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0[1.0]</text>\n",
       "<text text-anchor=\"middle\" x=\"29.5\" y=\"-186.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1[0.0]</text>\n",
       "<text text-anchor=\"middle\" x=\"29.5\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2[0.0]</text>\n",
       "<text text-anchor=\"middle\" x=\"29.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n",
       "</g>\n",
       "<!-- 8780664239824&#45;&gt;8780664248863 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>8780664239824&#45;&gt;8780664248863</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M46.9498,-297.7743C41.1645,-292.7379 35.8905,-286.7842 32.5,-280 26.7965,-268.5876 24.4413,-255.2952 23.8739,-242.5007\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"27.3727,-242.3562 23.7723,-232.3919 20.3731,-242.4266 27.3727,-242.3562\"/>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-268.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;2.45</text>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-253.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> conf=1.0 </text>\n",
       "</g>\n",
       "<!-- 8780664248857 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>8780664248857</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"187.5,-209.5 77.5,-209.5 77.5,-171.5 187.5,-171.5 187.5,-209.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"132.5\" y=\"-194.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> petal_length</text>\n",
       "<text text-anchor=\"middle\" x=\"132.5\" y=\"-179.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n",
       "</g>\n",
       "<!-- 8780664239824&#45;&gt;8780664248857 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>8780664239824&#45;&gt;8780664248857</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M95.9891,-297.6202C100.2172,-292.203 104.4038,-286.1167 107.5,-280 117.1232,-260.9886 123.4712,-237.7709 127.362,-219.7477\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"130.8205,-220.303 129.3751,-209.8072 123.9598,-218.9135 130.8205,-220.303\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-268.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;=2.45</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-253.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> conf=1.0 </text>\n",
       "</g>\n",
       "<!-- 8780664247495 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>8780664247495</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"113,-83 54,-83 54,0 113,0 113,-83\"/>\n",
       "<text text-anchor=\"middle\" x=\"83.5\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> class</text>\n",
       "<text text-anchor=\"middle\" x=\"83.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0[0.0]</text>\n",
       "<text text-anchor=\"middle\" x=\"83.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1[1.0]</text>\n",
       "<text text-anchor=\"middle\" x=\"83.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2[0.0]</text>\n",
       "<text text-anchor=\"middle\" x=\"83.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n",
       "</g>\n",
       "<!-- 8780664248857&#45;&gt;8780664247495 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>8780664248857&#45;&gt;8780664247495</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M111.565,-171.4476C101.3175,-160.6985 90.021,-146.3628 84.5,-131 80.2288,-119.115 78.5689,-105.7556 78.2926,-93.0559\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"81.7925,-93.0712 78.3442,-83.0533 74.7925,-93.035 81.7925,-93.0712\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-119.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;4.75</text>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-104.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> conf=1.0 </text>\n",
       "</g>\n",
       "<!-- 8780664247477 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>8780664247477</title>\n",
       "<polygon fill=\"none\" stroke=\"#ff0000\" points=\"211,-83 152,-83 152,0 211,0 211,-83\"/>\n",
       "<text text-anchor=\"middle\" x=\"181.5\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> class</text>\n",
       "<text text-anchor=\"middle\" x=\"181.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0[0.0]</text>\n",
       "<text text-anchor=\"middle\" x=\"181.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1[0.0]</text>\n",
       "<text text-anchor=\"middle\" x=\"181.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2[1.0]</text>\n",
       "<text text-anchor=\"middle\" x=\"181.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> </text>\n",
       "</g>\n",
       "<!-- 8780664248857&#45;&gt;8780664247477 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>8780664248857&#45;&gt;8780664247477</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.3049,-171.3075C147.8911,-159.8273 154.7096,-144.827 159.5,-131 163.6745,-118.9508 167.382,-105.7299 170.5086,-93.2345\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.9369,-93.9482 172.8895,-83.4053 167.1336,-92.3003 173.9369,-93.9482\"/>\n",
       "<text text-anchor=\"middle\" x=\"205\" y=\"-119.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&gt;=4.75</text>\n",
       "<text text-anchor=\"middle\" x=\"205\" y=\"-104.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> conf=1.0 </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7fc691895190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prind the uncertain local tree for the given instance\n",
    "import graphviz\n",
    "lux.uid3.tree.save_dot('tree.dot')\n",
    "graphviz.Source.from_file('tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "graph=sns.scatterplot(x='petal_length',y='petal_width', data=train[['petal_length','petal_width', target]],hue=target,s=100)\n",
    "graph.axhline(0.8,0, linestyle='--')\n",
    "graph.axvline(4.75)\n",
    "plt.scatter(data=pd.DataFrame(iris_instance,columns=features),x='petal_length',y='petal_width', marker='o', s=200)\n",
    "plt.title('Decision boundary created by LUX for particular instance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without SHAP support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick some instance from datasetr\n",
    "iris_instance = train[features].sample(1, random_state=42).values\n",
    "iris_instance\n",
    "\n",
    "#train lux on neighbourhood equal 30% instances\n",
    "lux = LUX(predict_proba = clf.predict_proba, neighborhood_size=int(len(train)*fraction),max_depth=2,  node_size_limit = 1, grow_confidence_threshold = 0 )\n",
    "lux.fit(train[features], train[target], instance_to_explain=iris_instance,class_names=[0,1,2])\n",
    "\n",
    "#see the justification of the instance being classified for a given class\n",
    "lux.justify(np.array(iris_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate decision tree score over this dataset\n",
    "import sys\n",
    "sys.path.append('./pyuid3')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pyuid3.data import Data\n",
    "data = Data.parse_dataframe(test[features+[target]])\n",
    "    \n",
    "predictions = [int(x.get_name()) for x in lux.uid3.predict(data.instances)]\n",
    "print(f'Accuracy : {accuracy_score(predictions, test[target])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have a look at the entire rule-based model that can be executed with https:://heartdroid.re\n",
    "print(lux.to_HMR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prind the uncertain local tree for the given instance\n",
    "import graphviz\n",
    "lux.uid3.tree.save_dot('tree.dot')\n",
    "graphviz.Source.from_file('tree.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In fact, the explanation above is overcomplicated\n",
    "The explanation can be made only using petal_lenght, but due to the greadiness of decision tree classifier, algorithm could not select correct split criterion for the fist place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "graph=sns.scatterplot(x='petal_length',y='petal_width', data=train[['petal_length','petal_width', target]],hue=target,s=100)\n",
    "graph.axhline(0.8,0, linestyle='--')\n",
    "graph.axvline(4.75)\n",
    "plt.scatter(data=pd.DataFrame(iris_instance,columns=features),x='petal_length',y='petal_width', marker='o', s=200)\n",
    "plt.title('Decision boundary created by LUX for particular instance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris example with SHAP values\n",
    "The explanation is more compact, and more consistend with the model, hence, the LUX tree with SHAP support obtains more accuray on the whole dataset, wing smaller than LUX tree without SHAP support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lux.lux import LUX\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "features = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "target = 'calss'\n",
    "\n",
    "#create daatframe with columns names as strings (LUX accepts only DataFrames withj string columns names)\n",
    "df_iris = pd.DataFrame(iris.data,columns=features)\n",
    "df_iris[target] = iris.target\n",
    "\n",
    "#train classifier\n",
    "train, test = train_test_split(df_iris, random_state=rs)\n",
    "clf = svm.SVC(probability=True,random_state=rs)\n",
    "clf.fit(train[features].values,train[target])\n",
    "clf.score(test[features].values,test[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmaxdf(df):\n",
    "    maxv = df.max()\n",
    "    return df/maxv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "explainer = shap.KernelExplainer(clf.predict_proba, train[features])\n",
    "shap_values = explainer.shap_values(train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, features=None, feature_names=features, max_display=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values=sum([abs(shap) for shap in shap_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_shap =minmaxdf(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train lux on neighbourhood equal 30% instances\n",
    "lux = LUX(predict_proba = clf.predict_proba,classifier=clf.predict_proba, neighborhood_size=int(len(train)*fraction),max_depth=2,  node_size_limit = 3, grow_confidence_threshold = 0 )\n",
    "lux.fit(train[features], train[target], X_importances = None,  instance_to_explain=iris_instance,class_names=[0,1,2],discount_importance=True)\n",
    "\n",
    "#see the justification of the instance being classified for a given class\n",
    "lux.justify(np.array(iris_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate decision tree score over this dataset\n",
    "import sys\n",
    "sys.path.append('./pyuid3')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pyuid3.data import Data\n",
    "data = Data.parse_dataframe(test[features+[target]])\n",
    "    \n",
    "predictions = [int(x.get_name()) for x in lux.uid3.predict(data.instances)]\n",
    "print(f'Accuracy : {accuracy_score(predictions, test[target])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prind the uncertain local tree for the given instance\n",
    "import graphviz\n",
    "lux.uid3.tree.save_dot('tree.dot')\n",
    "graphviz.Source.from_file('tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "graph=sns.scatterplot(x='petal_length',y='petal_width', data=train[['petal_length','petal_width',target]],hue=target, alpha=clf.predict_proba(train[features]).max(axis=1),s=100)\n",
    "graph.axvline(2.45)\n",
    "graph.axvline(4.75)\n",
    "plt.scatter(data=pd.DataFrame(iris_instance,columns=features),x='petal_length',y='petal_width', marker='o', s=200)\n",
    "plt.title('Decision boundary created by LUX for particular instance with SHAP support')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lux.lux import LUX\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import some data to play with\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = wine['feature_names']\n",
    "target = 'calss'\n",
    "rs=42\n",
    "\n",
    "#create daatframe with columns names as strings (LUX accepts only DataFrames withj string columns names)\n",
    "df_wine = pd.DataFrame(wine.data,columns=features)\n",
    "df_wine[target] = wine.target\n",
    "\n",
    "#train classifier\n",
    "train, test = train_test_split(df_wine, random_state=rs)\n",
    "clf = RandomForestClassifier(random_state=42)#svm.SVC(probability=True, random_state=rs)\n",
    "clf.fit(train[features],train[target])\n",
    "clf.score(test[features],test[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without predictor uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick some instance from datasetr\n",
    "iris_instance = train[features].sample(1, random_state=42).values\n",
    "iris_instance\n",
    "\n",
    "#train lux on neighbourhood equal 30% instances\n",
    "lux = LUX(predict_proba = lambda x: np.round(clf.predict_proba(x)), neighborhood_size=int(len(train)*fraction),max_depth=2,  node_size_limit = 1, grow_confidence_threshold = 0 )\n",
    "lux.fit(train[features], train[target], instance_to_explain=iris_instance,class_names=[0,1,2])\n",
    "\n",
    "#see the justification of the instance being classified for a given class\n",
    "lux.justify(np.array(iris_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate decision tree score over this dataset\n",
    "import sys\n",
    "sys.path.append('./pyuid3')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pyuid3.data import Data\n",
    "data = Data.parse_dataframe(test[features+[target]])\n",
    "    \n",
    "predictions = [int(x.get_name()) for x in lux.uid3.predict(data.instances)]\n",
    "print(f'Accuracy : {accuracy_score(predictions, test[target])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prind the uncertain local tree for the given instance\n",
    "import graphviz\n",
    "lux.uid3.tree.save_dot('tree.dot')\n",
    "graphviz.Source.from_file('tree.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick some instance from datasetr\n",
    "iris_instance = train[features].sample(1, random_state=42).values\n",
    "iris_instance\n",
    "\n",
    "#train lux on neighbourhood equal 20 instances\n",
    "lux = LUX(predict_proba = clf.predict_proba, neighborhood_size=int(len(train)*fraction),max_depth=2,  node_size_limit = 1, grow_confidence_threshold = 0 )\n",
    "lux.fit(train[features], train[target], instance_to_explain=iris_instance,class_names=[0,1,2])\n",
    "\n",
    "#see the justification of the instance being classified for a given class\n",
    "lux.justify(np.array(iris_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate decision tree score over this dataset\n",
    "import sys\n",
    "sys.path.append('./pyuid3')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pyuid3.data import Data\n",
    "data = Data.parse_dataframe(test[features+[target]])\n",
    "    \n",
    "predictions = [int(x.get_name()) for x in lux.uid3.predict(data.instances)]\n",
    "print(f'Accuracy : {accuracy_score(predictions, test[target])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prind the uncertain local tree for the given instance\n",
    "import graphviz\n",
    "lux.uid3.tree.save_dot('tree.dot')\n",
    "graphviz.Source.from_file('tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "graph=sns.scatterplot(x='od280/od315_of_diluted_wines',y='flavanoids', data=train[['od280/od315_of_diluted_wines','flavanoids',target]],hue=target, alpha=clf.predict_proba(train[features]).max(axis=1),s=100)\n",
    "plt.scatter(data=pd.DataFrame(iris_instance,columns=features),x='od280/od315_of_diluted_wines',y='flavanoids', marker='o', s=200)\n",
    "graph.axhline(1.4)\n",
    "graph.axvline(2.205)\n",
    "plt.title('Decision boundary created by LUX for particular instance without SHAP support')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "explainer = shap.TreeExplainer(clf, train[features])\n",
    "shap_values = explainer.shap_values(train[features],check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, features=None, feature_names=features, max_display=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values=sum([abs(shap) for shap in shap_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_shap =minmaxdf(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train lux on neighbourhood equal 20% instances\n",
    "lux = LUX(predict_proba = clf.predict_proba, neighborhood_size=int(len(train)*fraction),max_depth=2,  node_size_limit = 3, grow_confidence_threshold = 0 )\n",
    "lux.fit(train[features], train[target], X_importances = scaled_shap,  instance_to_explain=iris_instance,class_names=[0,1,2],discount_importance=True)\n",
    "\n",
    "#see the justification of the instance being classified for a given class\n",
    "lux.justify(np.array(iris_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate decision tree score over this dataset\n",
    "import sys\n",
    "sys.path.append('./pyuid3')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pyuid3.data import Data\n",
    "data = Data.parse_dataframe(test[features+[target]])\n",
    "    \n",
    "predictions = [int(x.get_name()) for x in lux.uid3.predict(data.instances)]\n",
    "print(f'Accuracy : {accuracy_score(predictions, test[target])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prind the uncertain local tree for the given instance\n",
    "import graphviz\n",
    "lux.uid3.tree.save_dot('tree.dot')\n",
    "graphviz.Source.from_file('tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "graph=sns.scatterplot(x='flavanoids',y='color_intensity', data=train[['flavanoids','color_intensity',target]],hue=target, alpha=clf.predict_proba(train[features]).max(axis=1),s=100)\n",
    "graph.axvline(1.4)\n",
    "graph.axhline(3.725)\n",
    "plt.scatter(data=pd.DataFrame(iris_instance,columns=features),x='flavanoids',y='color_intensity', marker='o', s=200)\n",
    "plt.title('Decision boundary created by LUX for particular instance SHAP support')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lux.lux import LUX\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import some data to play with\n",
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "features = [f.replace(\" \",\"_\") for f in cancer['feature_names']]\n",
    "target = 'calss'\n",
    "rs=42\n",
    "\n",
    "#create daatframe with columns names as strings (LUX accepts only DataFrames withj string columns names)\n",
    "df_cancer = pd.DataFrame(cancer.data,columns=features)\n",
    "df_cancer[target] = cancer.target\n",
    "\n",
    "#train classifier\n",
    "train, test = train_test_split(df_cancer, random_state=rs)\n",
    "clf = RandomForestClassifier(random_state=42)#svm.SVC(probability=True, random_state=rs)\n",
    "clf.fit(train[features],train[target])\n",
    "clf.score(test[features],test[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without predictor uncertinaty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick some instance from datasetr\n",
    "iris_instance = train[features].sample(1, random_state=42).values\n",
    "iris_instance\n",
    "\n",
    "#train lux on neighbourhood equal 30% instances\n",
    "lux = LUX(predict_proba = lambda x: np.round(clf.predict_proba(x)), neighborhood_size=int(len(train)*fraction),max_depth=2,  node_size_limit = 1, grow_confidence_threshold = 0 )\n",
    "lux.fit(train[features], train[target], instance_to_explain=iris_instance,class_names=[0,1])\n",
    "\n",
    "#see the justification of the instance being classified for a given class\n",
    "lux.justify(np.array(iris_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate decision tree score over this dataset\n",
    "import sys\n",
    "sys.path.append('./pyuid3')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pyuid3.data import Data\n",
    "data = Data.parse_dataframe(test[features+[target]])\n",
    "    \n",
    "predictions = [int(x.get_name()) for x in lux.uid3.predict(data.instances)]\n",
    "print(f'Accuracy : {accuracy_score(predictions, test[target])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prind the uncertain local tree for the given instance\n",
    "import graphviz\n",
    "lux.uid3.tree.save_dot('tree.dot')\n",
    "graphviz.Source.from_file('tree.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick some instance from datasetr\n",
    "iris_instance = train[features].sample(1, random_state=42).values\n",
    "iris_instance\n",
    "\n",
    "#train lux on neighbourhood equal 20% instances\n",
    "lux = LUX(predict_proba = clf.predict_proba, neighborhood_size=int(len(train)*fraction),max_depth=2,  node_size_limit = 1, grow_confidence_threshold = 0 )\n",
    "lux.fit(train[features], train[target], instance_to_explain=iris_instance,class_names=[0,1])\n",
    "\n",
    "#see the justification of the instance being classified for a given class\n",
    "lux.justify(np.array(iris_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate decision tree score over this dataset\n",
    "import sys\n",
    "sys.path.append('./pyuid3')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pyuid3.data import Data\n",
    "data = Data.parse_dataframe(test[features+[target]])\n",
    "    \n",
    "predictions = [int(x.get_name()) for x in lux.uid3.predict(data.instances)]\n",
    "print(f'Accuracy : {accuracy_score(predictions, test[target])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prind the uncertain local tree for the given instance\n",
    "import graphviz\n",
    "lux.uid3.tree.save_dot('tree.dot')\n",
    "graphviz.Source.from_file('tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "graph=sns.scatterplot(x='worst_perimeter',y='worst_concave_points', data=train[['worst_perimeter','worst_concave_points',target]],hue=target, alpha=clf.predict_proba(train[features]).max(axis=1),s=100)\n",
    "graph.axvline(105.95)\n",
    "graph.axhline(0.14)\n",
    "plt.scatter(data=pd.DataFrame(iris_instance,columns=features),x='worst_perimeter',y='worst_concave_points', marker='o',color='r', s=200)\n",
    "plt.title('Decision boundary created by LUX for particular instance without SHAP support')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "# this takes a minute or two since we are explaining over 30 thousand samples in a model with over a thousand trees\n",
    "\n",
    "\n",
    "explainer = shap.Explainer(clf)\n",
    "shap_values = explainer.shap_values(train[features],check_additivity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values,train[features])#, features=None, feature_names=features, max_display=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values=sum([abs(shap) for shap in shap_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_shap =minmaxdf(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train lux on neighbourhood equal 20% instances\n",
    "lux = LUX(predict_proba = clf.predict_proba, neighborhood_size=int(len(train)*fraction),max_depth=2,  node_size_limit = 3, grow_confidence_threshold = 0 )\n",
    "lux.fit(train[features], train[target], X_importances = scaled_shap,  instance_to_explain=iris_instance,class_names=[0,1],discount_importance=True)\n",
    "\n",
    "#see the justification of the instance being classified for a given class\n",
    "lux.justify(np.array(iris_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate decision tree score over this dataset\n",
    "import sys\n",
    "sys.path.append('./pyuid3')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pyuid3.data import Data\n",
    "data = Data.parse_dataframe(test[features+[target]])\n",
    "    \n",
    "predictions = [int(x.get_name()) for x in lux.uid3.predict(data.instances)]\n",
    "print(f'Accuracy : {accuracy_score(predictions, test[target])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prind the uncertain local tree for the given instance\n",
    "import graphviz\n",
    "lux.uid3.tree.save_dot('tree.dot')\n",
    "graphviz.Source.from_file('tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "graph=sns.scatterplot(x='worst_area',y='worst_concave_points', data=train[['worst_area','worst_concave_points',target]],hue=target, alpha=clf.predict_proba(train[features]).max(axis=1),s=100)\n",
    "graph.axvline(830.75)\n",
    "graph.axhline(0.14)\n",
    "plt.scatter(data=pd.DataFrame(iris_instance,columns=features),x='worst_area',y='worst_concave_points', marker='o',color='r', s=200)\n",
    "plt.title('Decision boundary created by LUX for particular instance with SHAP support')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lux.lux import LUX\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "features = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "target = 'calss'\n",
    "rs=42\n",
    "fraction=0.3\n",
    "\n",
    "#create daatframe with columns names as strings (LUX accepts only DataFrames withj string columns names)\n",
    "df_iris = pd.DataFrame(iris.data,columns=features)\n",
    "df_iris[target] = iris.target\n",
    "\n",
    "#train classifier\n",
    "train, test = train_test_split(df_iris, random_state=rs)\n",
    "clf = xgb.XGBClassifier()#svm.SVC(probability=True, random_state=rs)\n",
    "clf.fit(train[features].values,train[target])\n",
    "clf.score(test[features],test[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(clf.predict_proba, train[features])\n",
    "shap_values = explainer.shap_values(train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(shap_values[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_dict={}\n",
    "expected_dict={}\n",
    "expected_values = explainer.expected_value\n",
    "for i,v in enumerate(shap_values):\n",
    "    shap_dict[str(i)] = pd.DataFrame(v, columns = train.columns[:-1])\n",
    "    expected_dict[str(i)] = expected_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.concat(shap_dict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in d.iterrows():\n",
    "    print(r.index.get_level_values(1).nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(12).reshape(3,4).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.arange(12).reshape(3,4)).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lux Environment",
   "language": "python",
   "name": "luxenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
